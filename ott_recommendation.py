import pandas as pd
import numpy as np
import os
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import logging
from typing import Dict, List, Tuple
import pickle
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ì „ì—­ ìºì‹œ ë³€ìˆ˜
GENRE_EMBEDDINGS_CACHE = {}
CONTENT_EMBEDDINGS_CACHE = {}

def load_data(content_path='./data/train_data.csv', price_path='./data/ott_price.csv'):
    """ë°ì´í„° ë¡œë“œ í•¨ìˆ˜"""
    contents = pd.read_csv(content_path)
    prices = pd.read_csv(price_path)
    return contents, prices

def get_user_input(contents):
    """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° í•¨ìˆ˜ (CLIìš©)"""
    # ì´ìš© ê°€ëŠ¥í•œ base genre ëª©ë¡ ì¶œë ¥ - ì½¤ë§ˆë¡œ ë¶„ë¦¬ëœ ì¥ë¥´ ì²˜ë¦¬
    all_genres = []
    for genre_str in contents['genre'].dropna():
        all_genres.extend([g.strip() for g in genre_str.split(',')])
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    base_options = sorted(set(all_genres))

    print('ì§€ì› ê°€ëŠ¥í•œ ì¥ë¥´(ì½¤ë§ˆë¡œ ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥):', ', '.join(base_options))
    base_genres = [g.strip() for g in input('ì¥ë¥´ ì„ íƒ(ì˜í™”, ë“œë¼ë§ˆ, ì˜ˆëŠ¥ ë“±, ì—¬ëŸ¬ ê°œ ê°€ëŠ¥): ').split(',')]

    # ì„¸ë¶€ ì¥ë¥´ ì˜µì…˜
    detail_options = sorted({
        x.strip() for sub in contents['genre_detail'].dropna() for x in sub.split(',')
    })
    print('ì„¸ë¶€ ì¥ë¥´ ì˜µì…˜ ì˜ˆì‹œ(ì½¤ë§ˆë¡œ ì„ íƒ ê°€ëŠ¥):', ', '.join(detail_options[:10]), '...')
    detail_genres = [g.strip() for g in input('ì„ í˜¸ ì„¸ë¶€ ì¥ë¥´(ì½¤ë§ˆë¡œ êµ¬ë¶„): ').split(',')]

    age_group = input('ì—°ë ¹ëŒ€(ex: 20ëŒ€, 30ëŒ€): ').strip()
    gender = input('ì„±ë³„(male/female): ').strip()
    weekly_hours = float(input('ì£¼ê°„ OTT ì‹œì²­ ì‹œê°„(ì‹œê°„): '))
    budget = float(input('í•œ ë‹¬ ì˜ˆì‚°(ì›): '))

    return base_genres, detail_genres, age_group, gender, weekly_hours, budget

def estimate_runtime_hours(row):
    """ëŸ¬ë‹íƒ€ì„ì„ ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if pd.notna(row.get('runtime', None)):
        try:
            mins = int(str(row.runtime).replace('ë¶„','').strip())
            return mins / 60
        except:
            pass
    if pd.notna(row.get('episodes', None)):
        try:
            eps = int(str(row.episodes).replace('ë¶€ì‘','').strip())
            return eps * 1.0
        except:
            pass
    return 1.0

def load_language_model():
    """ì–¸ì–´ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    logger.info("ì–¸ì–´ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    model = SentenceTransformer(model_name)
    logger.info("ì–¸ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return model

def precompute_genre_embeddings(model, contents):
    """
    ëª¨ë“  ê³ ìœ  ì¥ë¥´ì— ëŒ€í•œ ì„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ìºì‹œì— ì €ì¥
    """
    logger.info("ì¥ë¥´ ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì¤‘...")
    
    # ëª¨ë“  ê³ ìœ  ì¥ë¥´ ìˆ˜ì§‘
    all_genres = set()
    for genre_str in contents['genre_detail'].dropna():
        for genre in genre_str.split(','):
            genre = genre.strip()
            if genre:
                all_genres.add(genre)
    
    all_genres = list(all_genres)
    logger.info(f"ì´ {len(all_genres)}ê°œ ì¥ë¥´ ì„ë² ë”© ê³„ì‚° ì¤‘...")
    
    # ë°°ì¹˜ë¡œ í•œë²ˆì— ì„ë² ë”© ê³„ì‚° (íš¨ìœ¨ì„± ì¦ëŒ€)
    if all_genres:
        embeddings = model.encode(all_genres, show_progress_bar=False, batch_size=32)
        
        # ìºì‹œì— ì €ì¥
        global GENRE_EMBEDDINGS_CACHE
        GENRE_EMBEDDINGS_CACHE = {
            genre: embedding for genre, embedding in zip(all_genres, embeddings)
        }
    
    logger.info(f"ì¥ë¥´ ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì™„ë£Œ: {len(GENRE_EMBEDDINGS_CACHE)}ê°œ")
    return GENRE_EMBEDDINGS_CACHE

def precompute_content_embeddings(contents):
    """
    ëª¨ë“  ì½˜í…ì¸ ì˜ ì¥ë¥´ ì¡°í•©ì— ëŒ€í•œ ì„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°
    """
    logger.info("ì½˜í…ì¸  ì¥ë¥´ ì¡°í•© ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì¤‘...")
    
    global CONTENT_EMBEDDINGS_CACHE
    
    for idx, row in contents.iterrows():
        genres = []
        if pd.notna(row.get('genre_detail')):
            genres = [g.strip() for g in row['genre_detail'].split(',') if g.strip()]
        
        if genres:
            # ì¥ë¥´ ì¡°í•©ì„ í‚¤ë¡œ ì‚¬ìš©
            genre_key = tuple(sorted(genres))
            
            # ì´ë¯¸ ê³„ì‚°ëœ ì¡°í•©ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ê³„ì‚°
            if genre_key not in CONTENT_EMBEDDINGS_CACHE:
                # ê°œë³„ ì¥ë¥´ ì„ë² ë”©ë“¤ì˜ í‰ê·  ê³„ì‚°
                genre_embeddings = []
                for genre in genres:
                    if genre in GENRE_EMBEDDINGS_CACHE:
                        genre_embeddings.append(GENRE_EMBEDDINGS_CACHE[genre])
                
                if genre_embeddings:
                    avg_embedding = np.mean(genre_embeddings, axis=0)
                    CONTENT_EMBEDDINGS_CACHE[genre_key] = avg_embedding
    
    logger.info(f"ì½˜í…ì¸  ì„ë² ë”© ì‚¬ì „ ê³„ì‚° ì™„ë£Œ: {len(CONTENT_EMBEDDINGS_CACHE)}ê°œ ì¡°í•©")

def calculate_genre_similarity_optimized(user_genres: List[str], content_genres: List[str]) -> float:
    """
    ìµœì í™”ëœ ì¥ë¥´ ìœ ì‚¬ë„ ê³„ì‚° (ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ì‚¬ìš©)
    """
    if not user_genres or not content_genres:
        return 0.0
    
    # ì‚¬ìš©ì ì¥ë¥´ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
    user_embeddings = []
    for genre in user_genres:
        if genre in GENRE_EMBEDDINGS_CACHE:
            user_embeddings.append(GENRE_EMBEDDINGS_CACHE[genre])
    
    # ì½˜í…ì¸  ì¥ë¥´ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
    content_embeddings = []
    for genre in content_genres:
        if genre in GENRE_EMBEDDINGS_CACHE:
            content_embeddings.append(GENRE_EMBEDDINGS_CACHE[genre])
    
    if not user_embeddings or not content_embeddings:
        return 0.0
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    user_embeddings = np.array(user_embeddings)
    content_embeddings = np.array(content_embeddings)
    
    similarity_matrix = cosine_similarity(user_embeddings, content_embeddings)
    max_similarities = np.max(similarity_matrix, axis=1)
    
    return float(np.mean(max_similarities))

def add_genre_embeddings(contents, model):
    """
    ì½˜í…ì¸  ë°ì´í„°í”„ë ˆì„ì— ì¥ë¥´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê³  ì„ë² ë”© ì‚¬ì „ ê³„ì‚°
    """
    logger.info("ì½˜í…ì¸  ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    
    # ì¥ë¥´ í…ìŠ¤íŠ¸ ì •ë¦¬
    contents['base_genre_clean'] = contents['genre'].fillna('')
    
    # ì¥ë¥´ ìƒì„¸ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    contents['genre_detail_list'] = contents['genre_detail'].fillna('').apply(
        lambda x: [genre.strip() for genre in x.split(',')] if x else []
    )
    
    # ì„ë² ë”© ì‚¬ì „ ê³„ì‚°
    precompute_genre_embeddings(model, contents)
    precompute_content_embeddings(contents)
    
    logger.info("ì½˜í…ì¸  ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
    return contents

def ott_recommendation_model(
        contents, 
        prices, 
        base_genres, 
        detail_genres, 
        age_group, gender, 
        weekly_hours, 
        budget, model):
    """
    ìµœì í™”ëœ ì¶”ì²œ ì‹œìŠ¤í…œ í•¨ìˆ˜ (ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ì‚¬ìš©)
    """
    max_hours = weekly_hours * 4    # ì›”ê°„ ì‹œì²­ ì‹œê°„
    desired_min, desired_max = 3, 8 # ì¶”ì²œ ì½˜í…ì¸  ê°œìˆ˜
    logger.info(f"ì‚¬ìš©ìì˜ ì›”ê°„ ì‹œì²­ ì‹œê°„: {max_hours:.1f}ì‹œê°„, ì¶”ì²œ ì½˜í…ì¸  ê°œìˆ˜: {desired_min}~{desired_max}ê°œ")

    logger.info("ì¶”ì²œ ë¶„ì„ ì‹œì‘...")
    
    # ê¸°ë³¸ í•„í„°ë§ (base ì¥ë¥´, ì—°ë ¹ëŒ€, ì„±ë³„)
    genre_mask = contents['genre'].apply(
        lambda x: any(genre in str(x).split(',') for genre in base_genres) if pd.notna(x) else False
    )
    age_gender_mask = (contents['age_group'] == age_group) & (contents['gender'] == gender)
    
    # í›„ë³´ ë°ì´í„°ì…‹ ìƒì„±
    candidates = contents[genre_mask & age_gender_mask].copy()
    
    # í•„í„° ì™„í™” ë¡œì§
    original_count = len(candidates)
    if original_count < desired_min:
        logger.info('ì½˜í…ì¸  ë¶€ì¡±: í•„í„° ì™„í™”')
        if original_count == 0:
            candidates = contents[genre_mask].copy()
        else:
            additional_candidates = contents[genre_mask & ~contents.index.isin(candidates.index)].copy()
            candidates = pd.concat([candidates, additional_candidates])
    
    if len(candidates) < desired_min:
        logger.info('ëª¨ë“  í•„í„° ì™„í™”')
        if len(candidates) == 0:
            candidates = contents.copy()
        else:
            additional_candidates = contents[~contents.index.isin(candidates.index)].copy()
            candidates = pd.concat([candidates, additional_candidates])
    
    if candidates.empty:
        logger.warning('ì¶”ì²œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.')
        return pd.DataFrame(), {}, 0, 0
    
    # ğŸš€ ìµœì í™”ëœ ì¥ë¥´ ìœ ì‚¬ë„ ê³„ì‚° (ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ì‚¬ìš©)
    logger.info("ì¥ë¥´ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
    genre_scores = []
    
    for _, row in candidates.iterrows():
        content_genres = row['genre_detail_list']
        similarity_score = calculate_genre_similarity_optimized(detail_genres, content_genres)
        genre_scores.append(similarity_score)
    
    candidates['genre_similarity'] = genre_scores
    
    # ëŸ¬ë‹íƒ€ì„ ê³„ì‚°
    candidates['watch_hours'] = candidates.apply(estimate_runtime_hours, axis=1)
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚°
    candidates['combined_score'] = (
        0.5 * candidates['genre_similarity'] +
        0.3 * (candidates['score'] / 100) +
        0.2 * (1 / (1 + candidates['watch_hours']))
    )
    
    # ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
    candidates = candidates.sort_values('combined_score', ascending=False)
    candidates = candidates.drop_duplicates(subset=['title'])
    
    # ê·¸ë¦¬ë”” ì„ íƒ
    selected = []
    total_hours = 0
    
    for _, row in candidates.iterrows():
        if total_hours + row.watch_hours > max_hours:
            continue
        selected.append(row)
        total_hours += row.watch_hours
        if len(selected) >= desired_max:
            break
    
    # ìµœì†Œ ê°œìˆ˜ ë³´ì¥
    if len(selected) < desired_min:
        top = candidates.head(desired_min)
        selected = [row for _, row in top.iterrows()]
        total_hours = sum(row.watch_hours for row in selected)
        logger.info(f'ì¢…í•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ {desired_min}ê°œ ì¶”ì²œ')
    
    sel_df = pd.DataFrame(selected)
    
    # í”Œë«í¼ ë° ìš”ê¸ˆì œ ê³„ì‚°
    plats = set()
    for entry in sel_df.platform.fillna('').tolist():
        for p in str(entry).split(','):
            name = p.strip()
            if name:
                plats.add(name)
    
    total_cost = 0
    plan = {}
    for p in plats:
        opts = prices[prices['ì„œë¹„ìŠ¤ëª…'] == p]
        if opts.empty:
            continue
        cheapest = opts.loc[opts['ì›” êµ¬ë…ë£Œ(ì›)'].idxmin()]
        plan[p] = (cheapest['ìš”ê¸ˆì œ'], cheapest['ì›” êµ¬ë…ë£Œ(ì›)'])
        total_cost += int(cheapest['ì›” êµ¬ë…ë£Œ(ì›)'])
    
    # === ì˜ˆì‚° ì´ˆê³¼ OTTë§Œ í¬í•¨ëœ ì½˜í…ì¸  ì œì™¸ ë° ëŒ€ì²´ ì¶”ì²œ ===
    over_budget_ott = set()
    if total_cost > budget:
        running_cost = 0
        for p, (plan_name, price) in plan.items():
            running_cost += int(price)
            if running_cost > budget:
                over_budget_ott.add(p)

    def is_only_on_over_budget_ott(platforms, over_budget_ott, all_ott):
        platform_set = set([pp.strip() for pp in str(platforms).split(',') if pp.strip()])
        # ì˜ˆì‚° ë‚´ OTTê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ False
        if platform_set - over_budget_ott:
            return False
        # ì˜ˆì‚° ì´ˆê³¼ OTTë§Œ ìˆìœ¼ë©´ True
        return bool(platform_set & over_budget_ott)

    if over_budget_ott:
        filtered = []
        for _, row in sel_df.iterrows():
            if not is_only_on_over_budget_ott(row['platform'], over_budget_ott, set(plan.keys())):
                filtered.append(row)
        # ëŒ€ì²´ ì½˜í…ì¸  ì¶”ê°€ (ì˜ˆì‚° ë‚´ OTTì— í¬í•¨ëœ ê²ƒ ì¤‘ì—ì„œ)
        if len(filtered) < desired_min:
            for _, row in candidates.iterrows():
                if not is_only_on_over_budget_ott(row['platform'], over_budget_ott, set(plan.keys())):
                    if row['title'] not in [r['title'] for r in filtered]:
                        filtered.append(row)
                    if len(filtered) >= desired_min:
                        break
        sel_df = pd.DataFrame(filtered)

    # =========================

    logger.info("ì¶”ì²œ ë¶„ì„ ì™„ë£Œ")
    return sel_df, plan, float(total_hours), int(total_cost)

def prepare_ott_recommendation_data():
    """
    OTT ì¶”ì²œì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ì™€ ì„ë² ë”©ì„ ì‚¬ì „ ì¤€ë¹„
    """
    logger.info("OTT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_language_model()
    
    # ë°ì´í„° ë¡œë“œ
    contents, prices = load_data()
    
    # ì„ë² ë”© ì‚¬ì „ ê³„ì‚° (ì—¬ê¸°ì„œ ëª¨ë“  ê³„ì‚° ì™„ë£Œ)
    contents = add_genre_embeddings(contents, model)
    
    logger.info("OTT ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    return contents, prices, model

def clear_cache():
    """ìºì‹œ ì •ë¦¬ í•¨ìˆ˜"""
    global GENRE_EMBEDDINGS_CACHE, CONTENT_EMBEDDINGS_CACHE
    GENRE_EMBEDDINGS_CACHE.clear()
    CONTENT_EMBEDDINGS_CACHE.clear()
    logger.info("ì„ë² ë”© ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# CLI ì‹¤í–‰ìš©
if __name__ == '__main__':
    print("=== ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘ ===")
    
    # ëª¨ë“  ë°ì´í„° ë° ì„ë² ë”© ì‚¬ì „ ì¤€ë¹„
    contents, prices, model = prepare_ott_recommendation_data()
    
    print("2. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°")
    base_genres, detail_genres, age_group, gender, weekly_hours, budget = get_user_input(contents)
    
    print("3. ì¶”ì²œ ì‹¤í–‰")
    sel_df, plan, hours, cost = ott_recommendation_model(
        contents, prices, base_genres, detail_genres,
        age_group, gender, weekly_hours, budget, model
    )
    
    if not sel_df.empty:
        print("\n=== ì¶”ì²œ êµ¬ë… í”Œëœ ===")
        for p, (pkg, c) in plan.items():
            print(f"- {p}: {pkg} / {c}ì›")
        print(f"ì´ êµ¬ë…ë¹„: {cost}ì›, ì˜ˆìƒ ì‹œì²­ì‹œê°„: {hours:.1f}ì‹œê°„\n")
        
        print("=== ì¶”ì²œ ì½˜í…ì¸  ===")
        for _, row in sel_df.iterrows():
            similarity_str = f"ì¥ë¥´ ìœ ì‚¬ë„: {row.get('genre_similarity', 0):.2f}" if 'genre_similarity' in row else ""
            print(f"- {row.get('title', '')} ({similarity_str})")
    else:
        print("\nì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
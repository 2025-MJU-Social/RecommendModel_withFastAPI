# recommendations.py
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel

import pandas as pd
def run_recommendation(age, sex, liked_titles):

    # ğŸ‘‰ ì—¬ê¸° ì „ì²´ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ë¶™ì—¬ ë„£ê³ 
    # ìµœì¢… ì¶”ì²œ ê²°ê³¼ë¥¼ return í•´ì£¼ë©´ ë¨
     # 1ì°¨ í›„ë³´êµ° ìƒì„±: ì¢‹ì•„í•˜ëŠ” ì½˜í…ì¸  ê¸°ë°˜ (ì¥ë¥´ ê¸°ë°˜ ì¶”ì²œ)
    contents = get_contents_data()
    preprocessing_contents = preprocessing_contents_data(contents)
    embeddings = get_embeddings(preprocessing_contents)
    contents_based_recommendations = genre_based_recommended_contents(contents, embeddings, liked_titles)

    # 2ì°¨ í›„ë³´êµ° ìƒì„±: ì‚¬ìš©ì í†µê³„ ê¸°ë°˜ (ì‚¬ìš©ìì˜ ì—°ë ¹/ì„±ë³„ ê¸°ë°˜ ì¶”ì²œ)
    user_based_recommendations = user_based_recommended_contents(age, sex)
    
    # í›„ë³´êµ° í†µí•©
    recommendations = merge_recommended_contents(preprocessing_contents, contents_based_recommendations, user_based_recommendations)

    # ì‚¬ìš©ì ì •ë³´ì— ë”°ë¼ ott ë³„ë¡œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    intentions = get_ott_intension_data()
    experiences = get_ott_experience_data()
    score_dict = calculate_ott_score(age, sex, intentions, experiences)

    # ì¶”ì²œëœ ì»¨í…ì¸ ë¥¼ ê¸°ë°˜í•œ ìµœì¢…ì ì¸ ott ì ìˆ˜ ê³„ì‚°
    result = get_ott_recommendation_ranking(recommendations, score_dict)

    print(result)
    
    return result.to_dict(orient='records')

# ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ í•„ë“œë¡œ ê²°í•©
def create_soup(row):
    soup = ' '.join(row['genre_detail'])
    return soup

# ì„ë² ë”© ë²¡í„° ê³„ì‚° í•¨ìˆ˜
def get_embeddings(preprocessing_contents):
    texts = preprocessing_contents['soup'].tolist()

    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)

    # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        # ëª¨ë¸ ì¶œë ¥ ì–»ê¸°
        outputs = model(**inputs)
        # í† í° ì„ë² ë”©ê³¼ ì–´í…ì…˜ ë§ˆìŠ¤í¬
        token_embeddings = outputs.last_hidden_state
        attention_mask = inputs["attention_mask"]

        # Mean Pooling ê³„ì‚°
        mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())
        sum_embeddings = torch.sum(token_embeddings * mask_expanded, dim=1)
        sum_mask = mask_expanded.sum(dim=1)
        embeddings = sum_embeddings / sum_mask
        
    return embeddings

# ì½˜í…ì¸  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
def get_contents_data():
    contents = pd.read_csv('data/fixed_contents.csv')
    contents = contents.fillna('')

    return contents
    
# ì½˜í…ì¸  ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬
def preprocessing_contents_data(contents):
    # ë‹¤ì¤‘ê°’ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    preprocessing_contents = contents.copy()
    multi_cols = ['genre_detail', 'director', 'platform', 'production', 'cast', 'country']
    for col in multi_cols:
        preprocessing_contents[col] = contents[col].apply(
            lambda x: sorted(x.split(', '))
        )
    preprocessing_contents['soup'] = preprocessing_contents.apply(create_soup, axis=1)

    return preprocessing_contents

# ì¥ë¥´ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸ ê²°ì •
def genre_based_recommended_contents(contents, embeddings, titles):
    print("genre_based_recommeded_contents í•¨ìˆ˜ ì‹œì‘")
    # ì¸ë±ìŠ¤ë¥¼ titleë¡œ ì„¤ì •
    temp = contents.reset_index()
    title_index = pd.Series(temp.index, index=temp['title']).drop_duplicates()

    # ìœ íš¨í•œ ì œëª©ë“¤ë§Œ ì¶”ì¶œ
    valid_indices = [title_index[title] for title in titles if title in title_index]

    if not valid_indices:
        return "ì…ë ¥ëœ ì œëª© ì¤‘ ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤."

    # ì„ íƒí•œ ì œëª©ë“¤ì˜ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
    selected_embeddings = embeddings[valid_indices]

    # ì…ë ¥ ì œëª©ë“¤ì˜ í‰ê·  ë²¡í„° ê³„ì‚°
    mean_embedding = selected_embeddings.mean(dim=0)

    # ëª¨ë“  ì½˜í…ì¸ ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    sim_scores = F.cosine_similarity(mean_embedding.unsqueeze(0), embeddings, dim=1)

    # ìœ ì‚¬ë„ ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ íŠœí”Œë¡œ ë¬¶ê³ , ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sim_scores = list(enumerate(sim_scores))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # ì…ë ¥ ì œëª© ìì²´ë¥¼ ì œì™¸í•˜ê³  ìƒìœ„ 5ê°œ ì¶”ì¶œ
    top_scores = [score for score in sim_scores if score[0] not in valid_indices][:5]

    # ì¶”ì²œ ì˜í™”ì˜ ì¸ë±ìŠ¤ì™€ ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ
    movie_indices = [i[0] for i in top_scores]
    similarity_scores = [i[1].item() for i in top_scores]

    # ì¶”ì²œ ì˜í™” ì œëª©ê³¼ ìœ ì‚¬ë„ ì ìˆ˜ ë°˜í™˜
    recommendations = contents['title'].iloc[movie_indices]

    # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
    contents_based_recommendations = pd.DataFrame({
        'title': recommendations,
        'similarity score': similarity_scores
    })

    # ìœ ì‚¬ë„ì— ë”°ë¥¸ weight ì¶”ê°€
    contents_based_recommendations['weight'] = range(5,0,-1)
    print("ì²˜ìŒ í•¨ìˆ˜ contents_based_recommendations type:", type(contents_based_recommendations))
    return contents_based_recommendations

# ì‚¬ìš©ì ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸ ê²°ì •
def user_based_recommended_contents(age, sex):
    user_data = None

    # ì„±ë³„ì— ë”°ë¥¸ ë°ì´í„° ë¡œë“œ
    if(sex=='m'):
        user_data = pd.read_csv('data/daily_MALE_250514.csv')
    else:
        user_data = pd.read_csv('data/daily_FEMALE_250514.csv')
        user_data = user_data.fillna('')

    # ì—°ë ¹ì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§
    if(age<20):
        user_data = user_data[user_data['age_group']=='10ëŒ€'][['rank','title']]
    elif(age<30):
        user_data = user_data[user_data['age_group']=='20ëŒ€'][['rank','title']]
    elif(age<40):
        user_data = user_data[user_data['age_group']=='30ëŒ€'][['rank','title']]
    elif(age<50):
        user_data = user_data[user_data['age_group']=='40ëŒ€'][['rank','title']]
    else:
        user_data = user_data[user_data['age_group']=='50ëŒ€'][['rank','title']]

    # ìœ ì €ì— ë”°ë¥¸ ì½˜í…ì¸  5ê°œ ì¶”ì²œ
    user_based_recommendations = user_data[:5]['title'].reset_index(drop=True).to_frame()
    user_based_recommendations['weight'] = range(5,0,-1)
    
    return user_based_recommendations

# ì¶”ì²œ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸ ê²°í•©
def merge_recommended_contents(preprocessing_contents, contents_based_recommendations, user_based_recommendations):
    print("user_based_recommendations type:", type(user_based_recommendations))
    print("contents_based_recommendations type:", type(contents_based_recommendations))

    # í›„ë³´êµ°ì„ ìœ„ì•„ë˜ë¡œ concat
    recommendations = pd.concat([user_based_recommendations, contents_based_recommendations], ignore_index=True, sort=False)

    # titleì´ ê²¹ì¹˜ë©´ weightê°€ í° ì»¨í…ì¸ ë¥¼ ë‚¨ê¹€
    idx = recommendations.groupby('title')['weight'].idxmax()
    recommendations = recommendations.loc[idx].reset_index(drop=True)

    # title, weight, platform ì •ë³´ë¥¼ ë‚¨ê¹€
    recommendations = recommendations[['title', 'weight']]
    recommendations = recommendations.merge(preprocessing_contents[["title", "platform"]], on="title", how="left")

    return recommendations

# OTT ì„œë¹„ìŠ¤ë³„ ì´ìš© ì˜í–¥ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
def get_ott_intension_data():
    # í•„ìš”í•œ ì •ë³´ë§Œ í•„í„°ë§
    intentions = pd.read_csv('data/OTT_ìœ ë£Œì„œë¹„ìŠ¤_ê³„ì†_ì´ìš©_ì˜í–¥__ì„œë¹„ìŠ¤ë³„_20250413203427.csv', encoding='euc-kr')
    intentions.columns = intentions.iloc[0]
    intentions=intentions.loc[19:]

    # ì»¬ëŸ¼ ì´ë¦„ í†µì¼
    intentions = intentions.rename(columns={"U+ëª¨ë°”ì¼ TV (%)": "U+ëª¨ë°”ì¼TV (%)"})

    # 50ëŒ€ ì´ìƒì€ í•˜ë‚˜ë¡œ ë¶„ë¥˜
    numeric_columns = intentions.columns[3:]
    intentions[numeric_columns] = intentions[numeric_columns].astype(float)
    sum_row = intentions.iloc[6:9, 3:].sum()
    intentions.loc[intentions['êµ¬ë¶„ë³„(2)'] == '50ëŒ€', intentions.columns[3:]] = sum_row.values
    intentions = intentions.iloc[:7]

    return intentions

# OTT ì„œë¹„ìŠ¤ë³„ ì´ìš© ê²½í—˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
def get_ott_experience_data():
    # í•„ìš”í•œ ì •ë³´ë§Œ í•„í„°ë§
    experiences = pd.read_csv('data/OTT_ì´ìš©_ê²½í—˜_ì—¬ë¶€_ì„œë¹„ìŠ¤ë³„_20250413203230.csv', encoding='euc-kr')
    experiences.columns = experiences.iloc[0]
    experiences=experiences.loc[19:]

    # 50ëŒ€ ì´ìƒì€ í•˜ë‚˜ë¡œ ë¶„ë¥˜
    numeric_columns = experiences.columns[3:]
    experiences[numeric_columns] = experiences[numeric_columns].astype(float)
    sum_row = experiences.iloc[6:9, 3:].sum()
    experiences.loc[experiences['êµ¬ë¶„ë³„(2)'] == '50ëŒ€', experiences.columns[3:]] = sum_row.values
    experiences = experiences.iloc[:7]

    return experiences

# ì‚¬ìš©ì ë°ì´í„°ì— ë”°ë¥¸ OTTë³„ ì ìˆ˜ ê³„ì‚°
def calculate_ott_score(age, sex, intentions, experiences):
    # ì‚¬ìš©ì ë°ì´í„°ì— ë§ëŠ” row ì¶”ì¶œ
    intentions_age_row = None
    intentions_gender_row = None
    experiences_age_row = None
    experiences_gender_row = None

    # ì„±ë³„ì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§
    if(sex=='m'):
        intentions_gender_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "ë‚¨ì"]
        experiences_gender_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "ë‚¨ì"]
    else:
        intentions_gender_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "ì—¬ì"]
        experiences_gender_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "ì—¬ì"]

    # ì—°ë ¹ì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§
    if(age<20):
        intentions_age_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "13~19ì„¸"]
        experiences_age_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "13~19ì„¸"]
    elif(age<30):
        intentions_age_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "20ëŒ€"]
        experiences_age_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "20ëŒ€"]
    elif(age<40):
        intentions_age_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "30ëŒ€"]
        experiences_age_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "30ëŒ€"]
    elif(age<50):
        intentions_age_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "40ëŒ€"]
        experiences_age_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "40ëŒ€"]
    else:
        intentions_age_row = intentions[intentions["êµ¬ë¶„ë³„(2)"] == "50ëŒ€"]
        experiences_age_row = experiences[experiences["êµ¬ë¶„ë³„(2)"] == "50ëŒ€"]

    # ì ìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    score_dict = {}

    # OTT ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸
    ott_services = ["ë„·í”Œë¦­ìŠ¤", "ì›¨ì´ë¸Œ", "í‹°ë¹™", "ì™“ì± ", "U+ëª¨ë°”ì¼TV", "ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡í”Œë ˆì´", "ì• í”ŒTV+"]

    # ê°€ì¤‘ì¹˜ ì„¤ì •
    weight_age = 0.5
    weight_gender = 0.5
    weight_experience = 0.6
    weight_intension = 0.4

    # scalingì„ ìœ„í•œ ë³€ìˆ˜
    max_score, min_score = 0, 1e9

    # ì¢…í•© ì ìˆ˜ ê³„ì‚°
    for ott in ott_services:
        # ì˜í–¥ ë° ê²½í—˜ ë°ì´í„° ì¶”ì¶œ
        intention_age = float(intentions_age_row[ott + " (%)"].values[0])
        experience_age = float(experiences_age_row[ott + " (%)"].values[0])
        intention_gender = float(intentions_gender_row[ott + " (%)"].values[0])
        experience_gender = float(experiences_gender_row[ott + " (%)"].values[0])

        # ê°ê°ì˜ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        score_age = weight_experience * experience_age + weight_intension * intention_age
        score_gender = weight_experience * experience_gender + weight_intension * intention_gender

        # ìµœì¢… ì¢…í•© ì ìˆ˜ ê³„ì‚°
        final_score = (weight_age * score_age) + (weight_gender * score_gender)

        if(ott=='ë„·í”Œë¦­ìŠ¤'):
            score_dict['Netflix']=final_score
        elif(ott=='ì›¨ì´ë¸Œ'):
            score_dict['Wavve']=final_score
        elif(ott=='í‹°ë¹™'):
            score_dict['TVING']=final_score
        elif(ott=='ì™“ì± '):
            score_dict['WATCHA']=final_score
        elif(ott=='U+ëª¨ë°”ì¼TV'):
            score_dict['U+ëª¨ë°”ì¼tv']=final_score
        elif(ott=='ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤'):
            score_dict['Disney+']=final_score
        elif(ott=='ì¿ íŒ¡í”Œë ˆì´'):
            score_dict['coupang play']=final_score
        elif(ott=='ì• í”ŒTV+'):
            score_dict['Apple TV+']=final_score

        max_score = max(max_score, final_score)
        min_score = min(min_score, final_score)

    # scaling (scoreê°€ 1ë³´ë‹¤ ì‘ìœ¼ë©´ weightì— ê³±í•´ì¡Œì„ ë•Œ ê°’ì´ ì‘ì•„ì§€ë¯€ë¡œ ìµœì†Œê°’ 1ì„ ë”í•¨)
    for k in score_dict:
        score_dict[k] = round((score_dict[k] - min_score) / (max_score - min_score) + 1, 2)

    return score_dict

# ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ëŠ” OTT í”Œë«í¼ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… OTT ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ OTT ì¶”ì²œ ìˆœìœ„ ë¶€ì—¬
def get_ott_recommendation_ranking(recommendations, score_dict):
    # sum of ((ì¶”ì²œëœ ì»¨í…ì¸ ë¥¼ ì œê³µí•˜ëŠ” ottë³„ ì¢…í•© ì ìˆ˜) * (ì¶”ì²œëœ ì»¨í…ì¸ ì˜ weight))
    ott_score=[0]*8
    for i in range(recommendations.shape[0]):
        for ott in recommendations.iloc[i].iloc[2]:
            if(ott=='Netflix'): ott_score[0] += score_dict['Netflix']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='Wavve'): ott_score[1] += score_dict['Wavve']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='TVING'): ott_score[2] += score_dict['TVING']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='WATCHA'): ott_score[3] += score_dict['WATCHA']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='U+ëª¨ë°”ì¼tv'): ott_score[4] += score_dict['U+ëª¨ë°”ì¼tv']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='Disney+'): ott_score[5] += score_dict['Disney+']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='coupang play'): ott_score[6] += score_dict['coupang play']*float(recommendations.iloc[i].iloc[1])
            elif(ott=='Apple TV+'): ott_score[7] += score_dict['Apple TV+']*float(recommendations.iloc[i].iloc[1])

    # score ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ott ì¶”ì²œ ìˆœìœ„ë¥¼ ë³´ê¸° ì‰½ê²Œ ë§Œë“¬
    ott_score_df = pd.DataFrame({'OTT': [ott for ott in score_dict],
                                'score': ott_score})
    result = ott_score_df.sort_values(by="score", ascending=False).reset_index(drop=True)
    
    return result